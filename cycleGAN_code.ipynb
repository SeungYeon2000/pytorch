{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycleGAN_code.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhKe4M62jK07Kr1rs+/SKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeungYeon2000/pytorch/blob/main/cycleGAN_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "-9cwbILD5yeq",
        "outputId": "d6df8fb4-1a33-4934-9862-a5fb089993c6"
      },
      "source": [
        "# discriminator\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Lambda, Concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD,Nadam, Adamax\n",
        "import keras.backend as K\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "class Discriminator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1, starting_filters=64):\n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.CAPACITY = width*height*channels\n",
        "        self.SHAPE = (width,height,channels)\n",
        "        self.FS = starting_filters #FilterStart\n",
        "        \n",
        "        self.Discriminator = self.model()\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
        "        self.Discriminator.compile(loss='mse', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
        "\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "\n",
        "    def model(self):\n",
        "\n",
        "\n",
        "        input_A = Input(shape=self.SHAPE)\n",
        "        input_B = Input(shape=self.SHAPE)\n",
        "        input_layer = Concatenate(axis=-1)([input_A, input_B])\n",
        "\n",
        "        up_layer_1 = Convolution2D(self.FS, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
        "\n",
        "        up_layer_2 = Convolution2D(self.FS*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(up_layer_1)\n",
        "        leaky_layer_2 =  BatchNormalization(momentum=0.8)(up_layer_2)\n",
        "\n",
        "        up_layer_3 = Convolution2D(self.FS*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_2)\n",
        "        leaky_layer_3 =  BatchNormalization(momentum=0.8)(up_layer_3)\n",
        "\n",
        "        up_layer_4 = Convolution2D(self.FS*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_3)\n",
        "        leaky_layer_4 = BatchNormalization(momentum=0.8)(up_layer_4)\n",
        "\n",
        "        output_layer = Convolution2D(1, kernel_size=4, strides=1, padding='same')(leaky_layer_4)\n",
        "        \n",
        "        return Model([input_A, input_B],output_layer)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Discriminator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Discriminator, to_file='/out/Discriminator_Model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6db953437320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNadam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_model' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE64qJ6Z6Azf"
      },
      "source": [
        "#gan\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import plot_model\n",
        "\n",
        "class GAN(object):\n",
        "    def __init__(self, model_inputs=[],model_outputs=[]):\n",
        "        self.OPTIMIZER = SGD(lr=2e-4,nesterov=True)\n",
        "\n",
        "        self.inputs = model_inputs\n",
        "        self.outputs = model_outputs\n",
        "        self.gan_model = Model(inputs = self.inputs, outputs = self.outputs)\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5)\n",
        "        self.gan_model.compile(loss=['mse', 'mae'],\n",
        "                            loss_weights=[  1, 100],\n",
        "                            optimizer=self.OPTIMIZER)\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "\n",
        "    def model(self):\n",
        "        model = Model()\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.gan_model.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.gan_model, to_file='/out/GAN_Model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4GlSeo16E9r"
      },
      "source": [
        "# generator\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Reshape, Input, BatchNormalization, Concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import UpSampling2D, Convolution2D, MaxPooling2D,Deconvolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD, Nadam,Adamax\n",
        "from keras import initializers\n",
        "from keras.utils import plot_model\n",
        "\n",
        "class Generator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1):\n",
        "        \n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.SHAPE = (width,height,channels)\n",
        "\n",
        "        self.Generator = self.model()\n",
        "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
        "        self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])\n",
        "\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "\n",
        "    def model(self):\n",
        "        input_layer = Input(shape=self.SHAPE)\n",
        "        \n",
        "        down_1 = Convolution2D(64  , kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
        "\n",
        "        down_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(down_1)\n",
        "        norm_2 = BatchNormalization()(down_2)\n",
        "\n",
        "        down_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_2)\n",
        "        norm_3 = BatchNormalization()(down_3)\n",
        "\n",
        "        down_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_3)\n",
        "        norm_4 = BatchNormalization()(down_4)\n",
        "\n",
        "        down_5 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_4)\n",
        "        norm_5 = BatchNormalization()(down_5)\n",
        "\n",
        "        down_6 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_5)\n",
        "        norm_6 = BatchNormalization()(down_6)\n",
        "\n",
        "        down_7 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_6)\n",
        "        norm_7 = BatchNormalization()(down_7)\n",
        "\n",
        "\n",
        "        upsample_1 = UpSampling2D(size=2)(norm_7)\n",
        "        up_conv_1 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_1)\n",
        "        norm_up_1 = BatchNormalization(momentum=0.8)(up_conv_1)\n",
        "        add_skip_1 = Concatenate()([norm_up_1,norm_6])\n",
        "\n",
        "\n",
        "        upsample_2 = UpSampling2D(size=2)(add_skip_1)\n",
        "        up_conv_2 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_2)\n",
        "        norm_up_2 = BatchNormalization(momentum=0.8)(up_conv_2)\n",
        "        add_skip_2 = Concatenate()([norm_up_2,norm_5])\n",
        "\n",
        "        upsample_3 = UpSampling2D(size=2)(add_skip_2)\n",
        "        up_conv_3 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_3)\n",
        "        norm_up_3 = BatchNormalization(momentum=0.8)(up_conv_3)\n",
        "        add_skip_3 = Concatenate()([norm_up_3,norm_4])\n",
        "\n",
        "\n",
        "        upsample_4 = UpSampling2D(size=2)(add_skip_3)\n",
        "        up_conv_4 = Convolution2D(64*4, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_4)\n",
        "        norm_up_4 = BatchNormalization(momentum=0.8)(up_conv_4)\n",
        "        add_skip_4 = Concatenate()([norm_up_4,norm_3])\n",
        "\n",
        "        upsample_5 = UpSampling2D(size=2)(add_skip_4)\n",
        "        up_conv_5 = Convolution2D(64*2, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_5)\n",
        "        norm_up_5 = BatchNormalization(momentum=0.8)(up_conv_5)\n",
        "        add_skip_5 = Concatenate()([norm_up_5,norm_2])\n",
        "\n",
        "        upsample_6 = UpSampling2D(size=2)(add_skip_5)\n",
        "        up_conv_6 = Convolution2D(64, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_6)\n",
        "        norm_up_6 = BatchNormalization(momentum=0.8)(up_conv_6)\n",
        "        add_skip_6 = Concatenate()([norm_up_6,down_1])\n",
        "\n",
        "        last_upsample = UpSampling2D(size=2)(add_skip_6)\n",
        "        output_layer = Convolution2D(self.C, kernel_size=4, strides=1, padding='same',activation='tanh')(last_upsample)\n",
        "        \n",
        "        return Model(input_layer,output_layer)\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Generator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Generator, to_file='/out/Generator_Model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wB4SuHV6Lpp"
      },
      "source": [
        "# run\n",
        "from train import Trainer\n",
        "\n",
        "# Command Line Argument Method\n",
        "HEIGHT  = 256\n",
        "WIDTH   = 256\n",
        "CHANNELS = 3\n",
        "EPOCHS = 100\n",
        "BATCH = 1\n",
        "CHECKPOINT = 50\n",
        "TRAIN_PATH = \"/data/cityscapes/cityscapes/train/\"\n",
        "TEST_PATH = \"/data/cityscapes/cityscapes/val/\"\n",
        "\n",
        "trainer = Trainer(height=HEIGHT,width=WIDTH, channels=CHANNELS,epochs =EPOCHS,\\\n",
        "                 batch=BATCH,\\\n",
        "                 checkpoint=CHECKPOINT,\\\n",
        "                 train_data_path=TRAIN_PATH,\\\n",
        "                 test_data_path=TEST_PATH)\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z4bmLpD6PSR"
      },
      "source": [
        "# save_to_npy\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
        "url = 'https://markinternational.info/data/out/366/221983609-black-hd-desktop-wallpaper.jpg'\n",
        "res = requests.get(url, headers=headers)\n",
        "with open('photo.jpg', 'wb') as W:\n",
        "    W.write(res.content)\n",
        "\n",
        "def grabListOfFiles(startingDirectory,extension=\".webp\"):\n",
        "    listOfFiles = []\n",
        "    for file in os.listdir(startingDirectory):\n",
        "        if file.endswith(extension):\n",
        "            listOfFiles.append(os.path.join(startingDirectory, file))\n",
        "    return listOfFiles\n",
        "\n",
        "def grabArrayOfImages(listOfFiles,resizeW=64,resizeH=64,gray=False):\n",
        "    imageArr = []\n",
        "    for f in listOfFiles:\n",
        "        if gray:\n",
        "            im = Image.open(f).convert(\"L\")\n",
        "        else:\n",
        "            im = Image.open(f).convert(\"RGB\")\n",
        "        im = im.resize((resizeW,resizeH))\n",
        "        imData = np.asarray(im)\n",
        "        imageArr.append(imData)\n",
        "    return imageArr\n",
        "\n",
        "direc = \"/data/church_outdoor_train_lmdb/expanded/\"\n",
        "listOfFiles = grabListOfFiles(direc)\n",
        "imageArrGray = grabArrayOfImages(listOfFiles,resizeW=64,resizeH=64,gray=True)\n",
        "imageArrColor = grabArrayOfImages(listOfFiles,resizeW=64,resizeH=64)\n",
        "print(\"Shape of ImageArr Gray: \", np.shape(imageArrGray))\n",
        "print(\"Shape of ImageArr Color: \", np.shape(imageArrColor))\n",
        "np.save('/data/church_outdoor_train_lmdb_gray.npy', imageArrGray)\n",
        "np.save('/data/church_outdoor_train_lmdb_color.npy', imageArrColor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy2bxVQb6SIz"
      },
      "source": [
        "# train\n",
        "from gan import GAN\n",
        "from generator import Generator\n",
        "from discriminator import Discriminator\n",
        "from keras.layers import Input\n",
        "from keras.datasets import mnist\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, height = 256, width = 256, channels=3, epochs = 50000, batch = 1, checkpoint = 50, train_data_path = '',test_data_path=''):\n",
        "        self.EPOCHS = epochs\n",
        "        self.BATCH = batch\n",
        "        self.H = height\n",
        "        self.W = width\n",
        "        self.C = channels\n",
        "        self.CHECKPOINT = checkpoint\n",
        "\n",
        "        self.X_train_B, self.X_train_A = self.load_data(train_data_path)\n",
        "        self.X_test_B, self.X_test_A  = self.load_data(test_data_path)\n",
        "\n",
        "\n",
        "        self.generator = Generator(height=self.H, width=self.W, channels=self.C)\n",
        "\n",
        "        self.orig_A = Input(shape=(self.W, self.H, self.C))\n",
        "        self.orig_B = Input(shape=(self.W, self.H, self.C))\n",
        "\n",
        "        self.fake_A = self.generator.Generator(self.orig_B)\n",
        "\n",
        "        self.discriminator = Discriminator(height=self.H, width=self.W, channels=self.C)\n",
        "        self.discriminator.trainable = False\n",
        "        self.valid = self.discriminator.Discriminator([self.fake_A,self.orig_B])\n",
        "\n",
        "        model_inputs  = [self.orig_A,self.orig_B]\n",
        "        model_outputs = [self.valid, self.fake_A]\n",
        "        self.gan = GAN(model_inputs=model_inputs,model_outputs=model_outputs)\n",
        "        \n",
        "        \n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        listOFFiles = self.grabListOfFiles(data_path,extension=\"jpg\")\n",
        "        imgs_temp = np.array(self.grabArrayOfImages(listOFFiles))\n",
        "        imgs_A = []\n",
        "        imgs_B = []\n",
        "        for img in imgs_temp:\n",
        "            imgs_A.append(img[:,:self.H])\n",
        "            imgs_B.append(img[:,self.H:])\n",
        "\n",
        "        imgs_A_out = self.norm_and_expand(np.array(imgs_A))\n",
        "        imgs_B_out = self.norm_and_expand(np.array(imgs_B))\n",
        "\n",
        "        return imgs_A_out, imgs_B_out\n",
        "\n",
        "    def norm_and_expand(self,arr):\n",
        "        arr = (arr.astype(np.float32) - 127.5)/127.5\n",
        "        normed = np.expand_dims(arr, axis=3)\n",
        "        return normed\n",
        "\n",
        "    def grabListOfFiles(self,startingDirectory,extension=\".webp\"):\n",
        "        listOfFiles = []\n",
        "        for file in os.listdir(startingDirectory):\n",
        "            if file.endswith(extension):\n",
        "                listOfFiles.append(os.path.join(startingDirectory, file))\n",
        "        return listOfFiles\n",
        "\n",
        "    def grabArrayOfImages(self,listOfFiles,gray=False):\n",
        "        imageArr = []\n",
        "        for f in listOfFiles:\n",
        "            if gray:\n",
        "                im = Image.open(f).convert(\"L\")\n",
        "            else:\n",
        "                im = Image.open(f).convert(\"RGB\")\n",
        "            imData = np.asarray(im)\n",
        "            imageArr.append(imData)\n",
        "        return imageArr\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        for e in range(self.EPOCHS):\n",
        "            b = 0\n",
        "            X_train_A_temp = deepcopy(self.X_train_A)\n",
        "            X_train_B_temp = deepcopy(self.X_train_B)\n",
        "\n",
        "            number_of_batches = len(self.X_train_A)\n",
        "        \n",
        "            for b in range(number_of_batches):\n",
        "                # Train Discriminator\n",
        "                # Grab Real Images for this training batch\n",
        "                starting_ind = randint(0, (len(X_train_A_temp)-1))\n",
        "                real_images_raw_A = X_train_A_temp[ starting_ind : (starting_ind + 1) ]\n",
        "                real_images_raw_B = X_train_B_temp[ starting_ind : (starting_ind + 1) ]\n",
        "\n",
        "                # Delete the images used until we have none left\n",
        "                X_train_A_temp = np.delete(X_train_A_temp,range(starting_ind,(starting_ind + 1)),0)\n",
        "                X_train_B_temp = np.delete(X_train_B_temp,range(starting_ind,(starting_ind + 1)),0)\n",
        "\n",
        "                batch_A = real_images_raw_A.reshape( 1, self.W, self.H, self.C )\n",
        "                batch_B = real_images_raw_B.reshape( 1, self.W, self.H, self.C )\n",
        "\n",
        "                # PatchGAN\n",
        "                y_valid = np.ones((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
        "                y_fake = np.zeros((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
        "\n",
        "                fake_A = self.generator.Generator.predict(batch_B)\n",
        "\n",
        "                # Now, train the discriminator with this batch of reals\n",
        "                discriminator_loss_real = self.discriminator.Discriminator.train_on_batch([batch_A,batch_B],y_valid)[0]\n",
        "                discriminator_loss_fake = self.discriminator.Discriminator.train_on_batch([fake_A,batch_B],y_fake)[0]\n",
        "                full_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "                generator_loss = self.gan.gan_model.train_on_batch([batch_A, batch_B],[y_valid,batch_A])    \n",
        "\n",
        "                print ('Batch: '+str(int(b))+', [Full Discriminator :: Loss: '+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
        "                if b % self.CHECKPOINT == 0 :\n",
        "                    label = str(e)+'_'+str(b)\n",
        "                    self.plot_checkpoint(label)\n",
        "\n",
        "            print ('Epoch: '+str(int(e))+', [Full Discriminator :: Loss:'+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
        "                        \n",
        "        return\n",
        "\n",
        "    def plot_checkpoint(self,b):\n",
        "        orig_filename = \"/out/batch_check_\"+str(b)+\"_original.png\"\n",
        "\n",
        "        r, c = 3, 3\n",
        "        random_inds = random.sample(range(len(self.X_test_A)),3)\n",
        "        imgs_A = self.X_test_A[random_inds].reshape(3, self.W, self.H, self.C )\n",
        "        imgs_B = self.X_test_B[random_inds].reshape( 3, self.W, self.H, self.C )\n",
        "        fake_A = self.generator.Generator.predict(imgs_B)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Style', 'Generated', 'Original']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[i])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"/out/batch_check_\"+str(b)+\".png\")\n",
        "        plt.close('all')\n",
        "\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}